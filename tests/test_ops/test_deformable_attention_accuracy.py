#!/usr/bin/env python3
"""
å¯å˜å½¢æ³¨æ„åŠ›ç²¾åº¦å¯¹æ¯”æµ‹è¯•

è¿™ä¸ªè„šæœ¬æ¯”è¾ƒPaddleåŸç‰ˆå®ç°å’ŒPyTorchè¿ç§»ç‰ˆæœ¬çš„å¯å˜å½¢æ³¨æ„åŠ›ç²¾åº¦ã€‚
æµ‹è¯•åŒ…æ‹¬ï¼š
1. ä½¿ç”¨é¢„å­˜çš„Paddleæµ‹è¯•æ•°æ®è¿›è¡Œæ•°å€¼å¯¹æ¯”
2. æ¯”è¾ƒCUDAä¼˜åŒ–å®ç°å’Œnaive grid_sampleå®ç°
3. ç”Ÿæˆè¯¦ç»†çš„ç²¾åº¦æŠ¥å‘Š

ç”¨æ³•:
    python test_deformable_attention_accuracy.py
"""

import os
import sys
import numpy as np
import torch
import torch.nn.functional as F
from typing import Tuple, Dict, Any
import warnings

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('/home/tyjt/æ¡Œé¢/migrate_paddle2pytorch/examples/rtdetrv3_pytorch')

def load_paddle_test_data() -> Dict[str, np.ndarray]:
    """
    åŠ è½½PaddleåŸç‰ˆç”Ÿæˆçš„æµ‹è¯•æ•°æ®
    
    Returns:
        dict: åŒ…å«æ‰€æœ‰æµ‹è¯•è¾“å…¥å’Œé¢„æœŸè¾“å‡ºçš„å­—å…¸
    """
    data_dir = "examples/ext_op/paddle_test_data"
    
    print(f"ğŸ“ ä» {data_dir} åŠ è½½Paddleæµ‹è¯•æ•°æ®...")
    
    # æ£€æŸ¥æ•°æ®ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(data_dir):
        raise FileNotFoundError(f"æµ‹è¯•æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
    
    # åŠ è½½æ‰€æœ‰æµ‹è¯•æ•°æ®æ–‡ä»¶
    files = [
        'value.npy',
        'spatial_shapes.npy', 
        'level_start_index.npy',
        'sampling_locations.npy',
        'attention_weights.npy',
        'output_cuda.npy'
    ]
    
    data = {}
    for filename in files:
        filepath = os.path.join(data_dir, filename)
        if os.path.exists(filepath):
            data[filename.replace('.npy', '')] = np.load(filepath)
            print(f"  âœ“ {filename}: shape {data[filename.replace('.npy', '')].shape}")
        else:
            print(f"  âœ— ç¼ºå°‘æ–‡ä»¶: {filename}")
    
    return data

def convert_numpy_to_torch(data: Dict[str, np.ndarray], device: str = 'cuda') -> Dict[str, torch.Tensor]:
    """
    å°†numpyæ•°ç»„è½¬æ¢ä¸ºPyTorchå¼ é‡
    
    Args:
        data: numpyæ•°æ®å­—å…¸
        device: ç›®æ ‡è®¾å¤‡
        
    Returns:
        dict: PyTorchå¼ é‡å­—å…¸
    """
    torch_data = {}
    
    for key, value in data.items():
        if key == 'spatial_shapes' or key == 'level_start_index':
            # è¿™äº›éœ€è¦æ˜¯int64ç±»å‹
            torch_data[key] = torch.from_numpy(value).to(dtype=torch.int64, device=device)
        else:
            # å…¶ä»–éƒ½æ˜¯float32
            torch_data[key] = torch.from_numpy(value).to(dtype=torch.float32, device=device)
    
    return torch_data

def test_cuda_implementation(torch_data: Dict[str, torch.Tensor]) -> Tuple[torch.Tensor, bool]:
    """
    æµ‹è¯•CUDAä¼˜åŒ–å®ç°
    
    Args:
        torch_data: æµ‹è¯•æ•°æ®
        
    Returns:
        tuple: (è¾“å‡ºå¼ é‡, æ˜¯å¦æˆåŠŸ)
    """
    try:
        print("\nğŸš€ æµ‹è¯•CUDAä¼˜åŒ–å®ç°...")
        
        from src.ops.ms_deform_attn import ms_deform_attn, is_available
        
        if not is_available():
            print("  âŒ CUDAæ‰©å±•æœªç¼–è¯‘æˆ–ä¸å¯ç”¨")
            return None, False
        
        output = ms_deform_attn(
            torch_data['value'],
            torch_data['spatial_shapes'],
            torch_data['level_start_index'],
            torch_data['sampling_locations'],
            torch_data['attention_weights']
        )
        
        print(f"  âœ… æˆåŠŸæ‰§è¡Œï¼Œè¾“å‡ºå½¢çŠ¶: {output.shape}")
        return output, True
        
    except Exception as e:
        print(f"  âŒ æ‰§è¡Œå¤±è´¥: {e}")
        return None, False

def test_naive_implementation(torch_data: Dict[str, torch.Tensor]) -> Tuple[torch.Tensor, bool]:
    """
    æµ‹è¯•naive grid_sampleå®ç°
    
    Args:
        torch_data: æµ‹è¯•æ•°æ®
        
    Returns:
        tuple: (è¾“å‡ºå¼ é‡, æ˜¯å¦æˆåŠŸ)
    """
    try:
        print("\nğŸ”„ æµ‹è¯•naive grid_sampleå®ç°...")
        
        from src.nn.transformer.layers import MSDeformableAttention
        
        # åˆ›å»ºMSDeformableAttentionå®ä¾‹
        bs, len_q, d_model = torch_data['sampling_locations'].shape[:3]
        n_heads = torch_data['sampling_locations'].shape[2]
        n_levels = torch_data['spatial_shapes'].shape[0]
        n_points = torch_data['sampling_locations'].shape[4]
        
        attn = MSDeformableAttention(
            d_model=d_model,
            n_heads=n_heads,
            n_levels=n_levels,
            n_points=n_points
        ).cuda()
        
        # å‡†å¤‡è¾“å…¥
        # æ³¨æ„ï¼šMSDeformableAttentionéœ€è¦queryä½œä¸ºè¾“å…¥
        query = torch.randn(bs, len_q, d_model, device='cuda')
        
        # è®¡ç®—reference points (ç®€åŒ–å¤„ç†)
        H, W = torch_data['spatial_shapes'][0].cpu().numpy()
        reference_points = torch.rand(bs, len_q, n_levels, 2, device='cuda')
        
        # ç›´æ¥ä½¿ç”¨æ ¸å¿ƒå‡½æ•°è¿›è¡Œæµ‹è¯•
        output = attn._deformable_attention_core_func(
            torch_data['value'],
            torch_data['spatial_shapes'],
            torch_data['level_start_index'],
            torch_data['sampling_locations'],
            torch_data['attention_weights']
        )
        
        print(f"  âœ… æˆåŠŸæ‰§è¡Œï¼Œè¾“å‡ºå½¢çŠ¶: {output.shape}")
        return output, True
        
    except Exception as e:
        print(f"  âŒ æ‰§è¡Œå¤±è´¥: {e}")
        return None, False

def compute_accuracy_metrics(pred: torch.Tensor, target: torch.Tensor) -> Dict[str, float]:
    """
    è®¡ç®—ç²¾åº¦æŒ‡æ ‡
    
    Args:
        pred: é¢„æµ‹å€¼
        target: ç›®æ ‡å€¼
        
    Returns:
        dict: ç²¾åº¦æŒ‡æ ‡å­—å…¸
    """
    pred_np = pred.detach().cpu().numpy()
    target_np = target.detach().cpu().numpy() if isinstance(target, torch.Tensor) else target
    
    # è®¡ç®—å„ç§è¯¯å·®æŒ‡æ ‡
    mae = np.mean(np.abs(pred_np - target_np))
    mse = np.mean((pred_np - target_np) ** 2)
    rmse = np.sqrt(mse)
    max_error = np.max(np.abs(pred_np - target_np))
    
    # ç›¸å¯¹è¯¯å·®
    target_norm = np.linalg.norm(target_np)
    if target_norm > 0:
        relative_error = np.linalg.norm(pred_np - target_np) / target_norm
    else:
        relative_error = float('inf')
    
    # ç›¸å…³æ€§
    pred_flat = pred_np.flatten()
    target_flat = target_np.flatten()
    correlation = np.corrcoef(pred_flat, target_flat)[0, 1] if len(pred_flat) > 1 else 1.0
    
    return {
        'mae': mae,
        'mse': mse, 
        'rmse': rmse,
        'max_error': max_error,
        'relative_error': relative_error,
        'correlation': correlation
    }

def print_accuracy_report(metrics: Dict[str, float], title: str):
    """
    æ‰“å°ç²¾åº¦æŠ¥å‘Š
    
    Args:
        metrics: ç²¾åº¦æŒ‡æ ‡
        title: æŠ¥å‘Šæ ‡é¢˜
    """
    print(f"\nğŸ“Š {title}")
    print("=" * 50)
    print(f"å¹³å‡ç»å¯¹è¯¯å·® (MAE):     {metrics['mae']:.8f}")
    print(f"å‡æ–¹è¯¯å·® (MSE):         {metrics['mse']:.8f}")
    print(f"å‡æ–¹æ ¹è¯¯å·® (RMSE):      {metrics['rmse']:.8f}")
    print(f"æœ€å¤§ç»å¯¹è¯¯å·®:          {metrics['max_error']:.8f}")
    print(f"ç›¸å¯¹è¯¯å·®:             {metrics['relative_error']:.8f}")
    print(f"ç›¸å…³ç³»æ•°:             {metrics['correlation']:.8f}")
    
    # ç»™å‡ºç²¾åº¦ç­‰çº§åˆ¤æ–­
    if metrics['relative_error'] < 1e-6:
        level = "ğŸŸ¢ æé«˜ç²¾åº¦ (< 1e-6)"
    elif metrics['relative_error'] < 1e-5:
        level = "ğŸŸ¡ é«˜ç²¾åº¦ (< 1e-5)"
    elif metrics['relative_error'] < 1e-4:
        level = "ğŸŸ  ä¸­ç­‰ç²¾åº¦ (< 1e-4)"
    elif metrics['relative_error'] < 1e-3:
        level = "ğŸ”´ ä½ç²¾åº¦ (< 1e-3)"
    else:
        level = "âš« ç²¾åº¦ä¸è¶³ (>= 1e-3)"
    
    print(f"ç²¾åº¦ç­‰çº§:             {level}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” RT-DETRv3 å¯å˜å½¢æ³¨æ„åŠ›ç²¾åº¦å¯¹æ¯”æµ‹è¯•")
    print("=" * 60)
    
    # æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨
    if not torch.cuda.is_available():
        print("âŒ CUDAä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œæµ‹è¯•")
        return
    
    print(f"âœ… ä½¿ç”¨è®¾å¤‡: {torch.cuda.get_device_name()}")
    
    try:
        # 1. åŠ è½½Paddleæµ‹è¯•æ•°æ®
        paddle_data = load_paddle_test_data()
        
        # æ£€æŸ¥å¿…è¦çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        required_keys = ['value', 'spatial_shapes', 'level_start_index', 
                        'sampling_locations', 'attention_weights', 'output_cuda']
        
        missing_keys = [key for key in required_keys if key not in paddle_data]
        if missing_keys:
            print(f"âŒ ç¼ºå°‘å¿…è¦çš„æµ‹è¯•æ•°æ®: {missing_keys}")
            return
        
        # 2. è½¬æ¢ä¸ºPyTorchå¼ é‡
        torch_data = convert_numpy_to_torch(paddle_data)
        paddle_output = torch_data['output_cuda']
        
        print(f"\nğŸ“‹ æµ‹è¯•æ•°æ®æ¦‚è¦:")
        print(f"  Batch size: {torch_data['value'].shape[0]}")
        print(f"  Value shape: {torch_data['value'].shape}")
        print(f"  Levels: {torch_data['spatial_shapes'].shape[0]}")
        print(f"  Expected output shape: {paddle_output.shape}")
        
        # 3. æµ‹è¯•CUDAå®ç°
        cuda_output, cuda_success = test_cuda_implementation(torch_data)
        
        # 4. æµ‹è¯•naiveå®ç°
        naive_output, naive_success = test_naive_implementation(torch_data)
        
        # 5. ç²¾åº¦å¯¹æ¯”
        print("\n" + "=" * 60)
        print("ğŸ¯ ç²¾åº¦å¯¹æ¯”ç»“æœ")
        
        if cuda_success and cuda_output is not None:
            cuda_metrics = compute_accuracy_metrics(cuda_output, paddle_output)
            print_accuracy_report(cuda_metrics, "CUDAå®ç° vs PaddleåŸç‰ˆ")
        else:
            print("\nâŒ CUDAå®ç°æµ‹è¯•å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œç²¾åº¦å¯¹æ¯”")
        
        if naive_success and naive_output is not None:
            naive_metrics = compute_accuracy_metrics(naive_output, paddle_output)
            print_accuracy_report(naive_metrics, "Naiveå®ç° vs PaddleåŸç‰ˆ")
        else:
            print("\nâŒ Naiveå®ç°æµ‹è¯•å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œç²¾åº¦å¯¹æ¯”")
        
        # 6. å®ç°é—´å¯¹æ¯”
        if cuda_success and naive_success and cuda_output is not None and naive_output is not None:
            inter_metrics = compute_accuracy_metrics(cuda_output, naive_output)
            print_accuracy_report(inter_metrics, "CUDAå®ç° vs Naiveå®ç°")
        
        # 7. æ€»ç»“
        print("\n" + "=" * 60)
        print("ğŸ“ æµ‹è¯•æ€»ç»“")
        
        if cuda_success:
            print("âœ… CUDAä¼˜åŒ–å®ç°: å¯ç”¨")
        else:
            print("âŒ CUDAä¼˜åŒ–å®ç°: ä¸å¯ç”¨")
            
        if naive_success:
            print("âœ… Naiveå¤‡é€‰å®ç°: å¯ç”¨")
        else:
            print("âŒ Naiveå¤‡é€‰å®ç°: ä¸å¯ç”¨")
        
        if cuda_success and cuda_metrics['relative_error'] < 1e-5:
            print("ğŸ‰ CUDAå®ç°ç²¾åº¦éªŒè¯é€šè¿‡!")
        elif cuda_success:
            print("âš ï¸  CUDAå®ç°ç²¾åº¦å¯èƒ½éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
        
        if naive_success and naive_metrics['relative_error'] < 1e-4:
            print("ğŸ‰ Naiveå®ç°ç²¾åº¦éªŒè¯é€šè¿‡!")
        elif naive_success:
            print("âš ï¸  Naiveå®ç°ç²¾åº¦åœ¨é¢„æœŸèŒƒå›´å†…")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()